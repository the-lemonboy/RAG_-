from langchain.chat_models import ChatOpenAI
from langchain.chains import ConversationChain
from langchain.schema import BaseCallbackHandler
from typing import Callable
from memory_store import get_memory

class StreamHandler(BaseCallbackHandler):
    def __init__(self, on_token: Callable[[str], None]):
        self.on_token = on_token

    def on_llm_new_token(self, token: str, **kwargs):
        self.on_token(token)

def get_chain(on_token: Callable[[str], None]):
    llm = ChatOpenAI(
        streaming=True,
        callbacks=[StreamHandler(on_token)],
        temperature=0.7,
    )
    memory = get_memory()
    return ConversationChain(
        llm=llm,
        memory=memory,
        verbose=True,
    )